{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Exercise 7.01: Factor Evolution"
      ],
      "metadata": {
        "id": "sMUC9YbPSAsj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BQiCl_tR6R-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FF Data Library file download\n",
        "\n",
        "url = 'https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_5_Factors_2x3_daily_csv.zip'\n",
        "\n",
        "# Specify the path where you want the file to be saved\n",
        "zip_path1 = 'F-F_Research_Data_5_Factors_2x3_daily_csv.zip'\n",
        "\n",
        "# Make HTTP request to download the file\n",
        "response = requests.get(url)\n",
        "with open(zip_path1, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "            print(f\"File downloaded and saved as: {zip_path1}\")\n",
        "\n",
        "with zipfile.ZipFile(zip_path1, 'r') as z:\n",
        "\n",
        "    # List the names of files in the ZIP to identify the CSV\n",
        "    csv_files = [f for f in z.namelist() if f.endswith('.csv')]\n",
        "    csv_file_name = csv_files[0]\n",
        "    z.extract(csv_file_name, '.')\n",
        "    print(f\"File '{csv_file_name}' extracted correctly.\")\n"
      ],
      "metadata": {
        "id": "wFoHUCuZSJ_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file, assuming the first column should be named 'Date'\n",
        "# and skipping the header\n",
        "\n",
        "filepath='F-F_Research_Data_5_Factors_2x3_daily.csv'\n",
        "factors = pd.read_csv(filepath, skiprows=3, low_memory=False)\n",
        "factors.rename(columns={factors.columns[0]: 'Date'}, inplace=True)\n",
        "factors.tail()\n"
      ],
      "metadata": {
        "id": "b_BcB_6vSNIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Momentum factor\n",
        "url = 'https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Momentum_Factor_daily_csv.zip'\n",
        "\n",
        "# Specify the path where you want the file to be saved\n",
        "zip_path2 = 'F-F_Momentum_Factor_daily_csv.zip'\n",
        "\n",
        "# Make HTTP request to download the file\n",
        "response = requests.get(url)\n",
        "with open(zip_path2, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "            print(f\"File downloaded and saved as: {zip_path2}\")\n",
        "\n",
        "with zipfile.ZipFile(zip_path2, 'r') as z:\n",
        "\n",
        "    # List the names of files in the ZIP to identify the CSV\n",
        "    csv_files2 = [f for f in z.namelist() if f.endswith('.csv')]\n",
        "    csv_file_name2 = csv_files2[0]\n",
        "    z.extract(csv_file_name2, '.')\n",
        "    print(f\"File '{csv_file_name2}' extracted correctly.\")\n"
      ],
      "metadata": {
        "id": "jwS4My6KSQvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load and clean the Momentum file ---\n",
        "filepath2 = 'F-F_Momentum_Factor_daily.csv'\n",
        "\n",
        "# Load the CSV file, skipping the non-data header rows\n",
        "momentum = pd.read_csv(filepath2, skiprows=13, low_memory=False)\n",
        "momentum.rename(columns={momentum.columns[0]: 'Date'}, inplace=True)\n",
        "\n",
        "# Extract only 8-digit date strings (YYYYMMDD)\n",
        "momentum['Date'] = (\n",
        "    momentum['Date']\n",
        "    .astype(str)\n",
        "    .str.extract(r'(\\d{8})', expand=False)\n",
        ")\n",
        "\n",
        "# Convert 'Date' to datetime format and drop invalid rows\n",
        "momentum['Date'] = pd.to_datetime(momentum['Date'], format='%Y%m%d', errors='coerce')\n",
        "momentum.dropna(subset=['Date'], inplace=True)\n",
        "\n",
        "\n",
        "# --- Clean the Fama-French 5 Factors file ---\n",
        "df1 = pd.DataFrame(factors).copy()\n",
        "df1.columns = df1.columns.str.strip()  # remove extra spaces in column names\n",
        "\n",
        "# Rename the date column if it appears with a different name (e.g., 'DATE')\n",
        "if 'Date' not in df1.columns:\n",
        "    date_col = [c for c in df1.columns if c.lower() == 'date']\n",
        "    if date_col:\n",
        "        df1.rename(columns={date_col[0]: 'Date'}, inplace=True)\n",
        "\n",
        "# Extract and convert date values to datetime\n",
        "df1['Date'] = (\n",
        "    df1['Date']\n",
        "    .astype(str)\n",
        "    .str.extract(r'(\\d{8})', expand=False)\n",
        ")\n",
        "df1['Date'] = pd.to_datetime(df1['Date'], format='%Y%m%d', errors='coerce')\n",
        "df1.dropna(subset=['Date'], inplace=True)\n",
        "\n",
        "# --- Merge both datasets on 'Date' ---\n",
        "df_combined = pd.merge(df1, momentum, on='Date', how='outer')\n",
        "\n",
        "# --- Sort and clean the merged DataFrame ---\n",
        "df_combined = df_combined.sort_values(by='Date').dropna()\n",
        "\n",
        "# --- Display the result ---\n",
        "print(df_combined.tail())\n"
      ],
      "metadata": {
        "id": "wmEWY6jhSSNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop 'ColumnName'\n",
        "df_combined.drop('RF', axis=1, inplace=True)\n",
        "df_combined.head()\n",
        "\n",
        "# Create a replacement dictionary\n",
        "replacement = {\n",
        "    'Mkt-RF': 'Market',\n",
        "    'SMB': 'Size',\n",
        "    'HML': 'Value',\n",
        "    'RMW': 'Quality',\n",
        "    'CMA': 'Investment',\n",
        "    'Mom'  : 'Momentum',\n",
        "    }\n",
        "# Rename headings\n",
        "df_combined.rename(columns=replacement, inplace=True)\n",
        "\n",
        "# See the new headings\n",
        "df_combined.tail()\n"
      ],
      "metadata": {
        "id": "Fsm3o77bSa8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering data by date\n",
        "start_date = pd.to_datetime('19800701',format='%Y%m%d')\n",
        "end_date = pd.to_datetime('20250829',format='%Y%m%d')\n",
        "try:\n",
        "    filtered_factors = df_combined[(df_combined['Date'] >= start_date) & (df_combined['Date'] <= end_date)]\n",
        "except TypeError as e:\n",
        "    print(\"TypeError encountered:\", e)\n",
        "    print(\"Re-checking the data types...\")\n",
        "    print(data.dtypes)  # This will help identify if there's still a data type issue.\n",
        "\n",
        "# Initialize base 100 for each factor\n",
        "accumulated_factors = filtered_factors.copy()\n",
        "\n",
        "# Start each column (factor) at 100 and accumulate daily changes\n",
        "for column in accumulated_factors.columns[1:]:\n",
        "    accumulated_factors[column] = 100 + accumulated_factors[column].cumsum()\n",
        "\n",
        "# Graph the cumulative evolution of each factor.\n",
        "plt.figure(figsize=(10, 6))\n",
        "for column in accumulated_factors.columns[1:]:\n",
        "    plt.plot(accumulated_factors['Date'], accumulated_factors[column], label=column)\n",
        "\n",
        "# Add title and tags\n",
        "plt.title('Cumulative Evolution of Factors with Base 100')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Index(Base 100)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n"
      ],
      "metadata": {
        "id": "M4LsV3BS91Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========  CORRELATIONS BETWEEN FACTORS  =============\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "def compute_correlations(df: pd.DataFrame, method: str = \"pearson\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate the correlation matrix between the factors..\n",
        "    method: 'pearson' (lineal), 'spearman' (ranges) or 'kendall'.\n",
        "    \"\"\"\n",
        "    # Only numeric columns and no excessive NaNs\n",
        "    df_num = df.select_dtypes(include=[np.number]).dropna(how=\"any\")\n",
        "    corr = df_num.corr(method=method)\n",
        "    return corr\n",
        "\n",
        "def plot_correlation_heatmap(corr: pd.DataFrame, title: str = \"Correlation between factors\") -> None:\n",
        "    \"\"\"\n",
        "    Plots a heat map of the correlation matrix.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---------- Calculation ----------\n",
        "corr_factors = compute_correlations(df_combined)\n",
        "print(\"Correlation matrix (Pearson):\")\n",
        "print(corr_factors.round(3))\n",
        "\n",
        "# ---------- Heat map ----------\n",
        "plot_correlation_heatmap(corr_factors, title=\"Factor Correlations in USA (daily)\")\n"
      ],
      "metadata": {
        "id": "U2JrpKQm2Efq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}